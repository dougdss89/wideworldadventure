<configuration>
  <!-- Configuração do sistema de arquivos padrão -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://delta-cluster</value>
  </property>

  <!-- Diretório de edições do JournalNode -->
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/home/hadoop/ha/data/jn</value>
  </property>

  <!-- Configuração do Zookeeper para HA -->
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>deltamasternode.hdp.com:2181,deltasecondnode.hdp.com:2181,deltadatanode.hdp.com:2181</value>
  </property>

  <!-- Failover configurado para o cluster HA -->
  <property>
    <name>dfs.client.failover.proxy.provider.delta-cluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>

  <!-- Métodos de fencing para evitar o split-brain no failover, --> 
   !-- para que outro não tente assumir ao retornar -->
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/hadoop/.ssh/id_rsa</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.connect-timeout</name>
    <value>30000</value>
  </property>

  <!-- Iceberg Configuration for Delta Lake -->
  <!-- Diretório do Iceberg no HDFS -->
  <property>
    <name>iceberg.catalog.hadoop.warehouse</name>
    <value>hdfs://delta-cluster/user/hive/warehouse</value>
  </property>

  <!-- Tipo de catalog para gerenciamento de tabelas com Iceberg -->
  <property>
    <name>iceberg.catalog.hadoop</name>
    <value>org.apache.iceberg.hadoop.HadoopCatalog</value>
  </property>

  <!-- Configurações de compactação para otimizar o armazenamento -->
  <property>
    <name>io.compression.codecs</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.GzipCodec</value>
  </property>

  <!-- Timeout de sessões e estabilidade no failover -->
  <property>
    <name>dfs.namenode.rpc-address.delta-cluster.dlt1</name>
    <value>deltacluster.hdp.com:8020</value>
  </property>

  <property>
    <name>dfs.namenode.rpc-address.delta-cluster.dlt2</name>
    <value>deltasecondnode.hdp.com:8020</value>
  </property>

  <!-- Configuração de failover automático -->
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>

  <!-- Caminho otimizado para checkpoints -->
  <property>
    <name>dfs.namenode.checkpoint.dir</name>
    <value>/home/hadoop/ha/data/nn/checkpoint</value>
  </property>

</configuration>

